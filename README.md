# Opening the Bottleneck

This repository hosts the public project page for **Opening the Bottleneck: Steering LLMs via Concept Intervention**, a UC San Diego HDSI capstone project (Winter 2026).

## Project Overview
Modern language models are powerful but difficult to interpret and control. This project explores a concept-bottleneck approach where model behavior is made more legible through interpretable concept activations and direct interventions.

The page presents:
- Why interpretable control matters for language-model reliability
- A high-level explanation of our concept intervention approach
- Key findings from replication and intervention experiments
- Citation information and links to code/tools

## Team
- Neil Dandekar — nmdandekar@ucsd.edu
- Christian Guerra — chguerra@ucsd.edu

## Advisor
- Lily Weng — lweng@ucsd.edu

## Links
- Live tool: https://chguerra15.github.io/capstone-site/
- Code and report: https://github.com/neil-dandekar/capstone

## Citation
If you build on this work, please cite:

```bibtex
@misc{hdsicapstone2026,
  title        = {Opening the Bottleneck: Steering LLMs via Concept Intervention},
  author       = {Dandekar, Neil and Guerra, Christian and Weng, Lily},
  year         = {2026},
  note         = {UC San Diego DSC 180AB Capstone},
  howpublished = {\url{https://github.com/neil-dandekar/capstone}}
}
```
